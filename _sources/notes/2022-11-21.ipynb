{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4689fcb1",
   "metadata": {},
   "source": [
    "# Intro to NLP- representing text data\n",
    "\n",
    "```{important}\n",
    "Wednesday class will be on zoom, using the office hours link that you can find on the course [GitHub Organization Page](https://github.com/rhodyprog4ds)\n",
    "\n",
    "**If you do not see a list of links at the top, you might need to accept an invite**\n",
    "\n",
    "The link will also be sent on prismia at class time.\n",
    "\n",
    "Wednesday office hours will be 3-4:30pm instead of 7-8:30pm\n",
    "```\n",
    "\n",
    "## Confidence Intervals review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbda8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def classification_confint(acc, n):\n",
    "      '''\n",
    "      Compute the 95% confidence interval for a classification problem.\n",
    "       acc -- classification accuracy\n",
    "       n  -- number of observations used to compute the accuracy\n",
    "      Returns a tuple (lb,ub)\n",
    "      '''\n",
    "      interval = 1.96*np.sqrt(acc*(1-acc)/n)\n",
    "      lb = max(0, acc - interval)\n",
    "      ub = min(1.0, acc + interval)\n",
    "      return (lb,ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2475c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21398e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6651767828355258, 0.8948232171644742),\n",
       " (0.816844242532462, 0.983155757467538))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_confint(.78,N) , classification_confint(.9,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e1cc2",
   "metadata": {},
   "source": [
    "These overlap, so they are not differnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24065305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.722588391417763, 0.8374116085822371),\n",
       " (0.8584221212662311, 0.941577878733769))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 200\n",
    "classification_confint(.78,N) , classification_confint(.9,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b96946",
   "metadata": {},
   "source": [
    "with more samples the intervals shrink and they stop overlapping\n",
    "\n",
    "\n",
    "## Text as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b08c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32455446",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = ['The class is just starting to feel settled for me. - Dr. Brown',\n",
    " 'Hello, I like sushi! - ',\n",
    " 'Why squared  aka the mask - is a computer science student.Data science is fun',\n",
    " 'Hello my fellow gaymers - Sun Tzu',\n",
    " 'Soccer is a sport -Obama',\n",
    " 'Hello, I love pizza - Bear',\n",
    " 'This class is CSC/DSP 310. - Student',\n",
    " 'It is 2:21pm -',\n",
    " 'Pizza conquers all- Beetlejuice',\n",
    " 'ayyy whaddup wit it - frankie',\n",
    " 'This is a sentence - George W Bush',\n",
    " 'Steam is the best place to play videogames change my mind. - Todd Howard',\n",
    " 'This is a hello -',\n",
    " 'Hello how are you -',\n",
    " 'The monkey likes bananas. - A banana',\n",
    " 'Just type a random sentence - Rosa Parks',\n",
    " 'I love CSC. - Everyone',\n",
    " 'The quick brown fox jumps over the lazy dog - Brendan Chadwick',\n",
    " 'I like computers - David',\n",
    " 'The fitness gram pacer test is a multi aerobic capacity test - Matt 3',\n",
    " 'Sally sells seashells by the seashore. - Narrator',\n",
    " 'I would like to take a nap. - Tom Cruise,']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a3fc7",
   "metadata": {},
   "source": [
    "How can we analyze these? All of the machine leanring models we have seen only use numerical features organized into a table with one row per samplea and one column per feature.\n",
    "\n",
    "That's actually generally true.  ALl ML models require numerical features, at some point. The process of taking data that is not numerical and tabular, which is called unstrucutred, into strucutred (tabular) format we require is called feature extraction.  There are many, many ways to do that.  We'll see a few over the course of the rest of the semester.  Some more advanced models hide the feature extraction, by putting it in the same function, but it's always there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "562b47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[s.split('-') for s in sentence_list],\n",
    "                 columns = ['sentence','attribution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc26e03",
   "metadata": {},
   "source": [
    "We can make it a dataframe, but we cannot use statistics on this because it is still sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b89833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The class is just starting to feel settled for...</td>\n",
       "      <td>Dr. Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello, I like sushi!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why squared  aka the mask</td>\n",
       "      <td>is a computer science student.Data science is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello my fellow gaymers</td>\n",
       "      <td>Sun Tzu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soccer is a sport</td>\n",
       "      <td>Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello, I love pizza</td>\n",
       "      <td>Bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This class is CSC/DSP 310.</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It is 2:21pm</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pizza conquers all</td>\n",
       "      <td>Beetlejuice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ayyy whaddup wit it</td>\n",
       "      <td>frankie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This is a sentence</td>\n",
       "      <td>George W Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Steam is the best place to play videogames cha...</td>\n",
       "      <td>Todd Howard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>This is a hello</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hello how are you</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The monkey likes bananas.</td>\n",
       "      <td>A banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Just type a random sentence</td>\n",
       "      <td>Rosa Parks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I love CSC.</td>\n",
       "      <td>Everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog</td>\n",
       "      <td>Brendan Chadwick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I like computers</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The fitness gram pacer test is a multi aerobic...</td>\n",
       "      <td>Matt 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sally sells seashells by the seashore.</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I would like to take a nap.</td>\n",
       "      <td>Tom Cruise,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "0   The class is just starting to feel settled for...   \n",
       "1                               Hello, I like sushi!    \n",
       "2                          Why squared  aka the mask    \n",
       "3                            Hello my fellow gaymers    \n",
       "4                                  Soccer is a sport    \n",
       "5                                Hello, I love pizza    \n",
       "6                         This class is CSC/DSP 310.    \n",
       "7                                       It is 2:21pm    \n",
       "8                                  Pizza conquers all   \n",
       "9                                ayyy whaddup wit it    \n",
       "10                                This is a sentence    \n",
       "11  Steam is the best place to play videogames cha...   \n",
       "12                                   This is a hello    \n",
       "13                                 Hello how are you    \n",
       "14                         The monkey likes bananas.    \n",
       "15                       Just type a random sentence    \n",
       "16                                       I love CSC.    \n",
       "17       The quick brown fox jumps over the lazy dog    \n",
       "18                                  I like computers    \n",
       "19  The fitness gram pacer test is a multi aerobic...   \n",
       "20            Sally sells seashells by the seashore.    \n",
       "21                       I would like to take a nap.    \n",
       "\n",
       "                                          attribution  \n",
       "0                                           Dr. Brown  \n",
       "1                                                      \n",
       "2    is a computer science student.Data science is...  \n",
       "3                                             Sun Tzu  \n",
       "4                                               Obama  \n",
       "5                                                Bear  \n",
       "6                                             Student  \n",
       "7                                                      \n",
       "8                                         Beetlejuice  \n",
       "9                                             frankie  \n",
       "10                                      George W Bush  \n",
       "11                                        Todd Howard  \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                           A banana  \n",
       "15                                         Rosa Parks  \n",
       "16                                           Everyone  \n",
       "17                                   Brendan Chadwick  \n",
       "18                                              David  \n",
       "19                                             Matt 3  \n",
       "20                                           Narrator  \n",
       "21                                        Tom Cruise,  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36778116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Soccer is a sport -Obama'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = sentence_list[4]\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040ddf3",
   "metadata": {},
   "source": [
    "## Terms\n",
    "\n",
    "\n",
    "- document: unit of text we’re analyzing (one sample)\n",
    "- token: sequence of characters in some particular document that are grouped together as a useful semantic unit for processing (basically a word)\n",
    "- stop words: no meaning, we don’t need them (like a, the, an,). Note that this is context dependent\n",
    "- dictionary: all of the possible words that a given system knows how to process\n",
    "\n",
    "\n",
    "\n",
    "## Bag of Words Representionat\n",
    "\n",
    "We're going to learn a represetnation called the bag of words.  It ignores the order of the words within a document. To do this, we'll first extract all of the tokens (tokenize) the docuemtns and then count how mnay times each word appears.  This will be our numerical representation of the data.  \n",
    "\n",
    "````{margin}\n",
    "```{admonition} Further Reading\n",
    "[Transformers](https://scikit-learn.org/stable/data_transforms.html) are another broad class of sklearn objects.  We've seen Estimators mostly so far.\n",
    "We're focusing on the [text feature extraction](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) for now.\n",
    "```\n",
    "````\n",
    "Then we initialize our transformer, and use the fit transform method to fit the vectorizer model and apply it to this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "911642c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = CountVectorizer()\n",
    "counts.fit_transform([s1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f3726",
   "metadata": {},
   "source": [
    "We see it returns a sparse matrix.  A sparse matrix means that it has a lot of 0s in it and so we only represent the data.  \n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd67f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfull = np.asarray([[1,0,0,0,0],[0,0,1,0,0],[0,0,0,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006a8f6",
   "metadata": {},
   "source": [
    "but as a sparse matrix, we could store fewer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8cc768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1], [1, 2, 1], [2, 3, 1]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[0,0,1],[1,2,1],[2,3,1]]# the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be972f9",
   "metadata": {},
   "source": [
    "So any matrix where the number of total values is low enough, we can store it more efficiently by tracking the locations and values instead of all of the zeros.\n",
    "\n",
    "To actually see it though we have to cast out of that into a regular array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aebf2f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.fit_transform([s1]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e807e",
   "metadata": {},
   "source": [
    "For only one sentence it's all ones, because it only has a small vocabulary.\n",
    "\n",
    "We can make it more interesting, by picking a second sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdcd2906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = sentence_list[19]\n",
    "counts.fit_transform([s1,s2]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e81af",
   "metadata": {},
   "source": [
    "We can also examine attributes of the object.\n",
    "````{margin}\n",
    "```{tip}\n",
    "Notice that we keep using the same tools over and over to explore how things work.  You can do this on your own, when you're learning new things. Example\n",
    "code is readily available online but not all of it is well documented or\n",
    "clearly explained.\n",
    "\n",
    "Also, in a job, much, much, more of your time will be spent reading code than writing code from scratch. These strategies will help you get familiar with a new code base and get up to speed faster.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "634a23c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'soccer': 9,\n",
       " 'is': 4,\n",
       " 'sport': 10,\n",
       " 'obama': 7,\n",
       " 'the': 12,\n",
       " 'fitness': 2,\n",
       " 'gram': 3,\n",
       " 'pacer': 8,\n",
       " 'test': 11,\n",
       " 'multi': 6,\n",
       " 'aerobic': 0,\n",
       " 'capacity': 1,\n",
       " 'matt': 5}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331694e",
   "metadata": {},
   "source": [
    "We see that what it does is creates an ordered (the values are the order) list of words as the parameters of this model (ending in `_` is an attribute of the object or parameter of the model).\n",
    "\n",
    "it puts the words in the `vocabulary_` attribute (aka the {term}`dictionary`) in alphabetical order.\n",
    "\n",
    "Now we can transform the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa4fd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = counts.fit_transform(df['sentence']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a8cd2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b06971",
   "metadata": {},
   "source": [
    "From this we can see that the representation is the count of how many times each word appears.\n",
    "\n",
    "Now we can apply it to all of the sentences, or our whole {term}`corpus`. We can get the dictionary out in order using the `get_feature_names` method. This method has a generic name, not specific to text, because it's a property of transformers in general.\n",
    "\n",
    "We can use a dataframe again to see this more easily. We can put labels on both the index and the column headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a45554",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sentence_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(mat, columns\u001b[38;5;241m=\u001b[39m\u001b[43mcounts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m(),index\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattribution\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m sentence_df\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "sentence_df = pd.DataFrame(mat, columns=counts.get_feature_names(),index= df['attribution'])\n",
    "sentence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7e2fa",
   "metadata": {},
   "source": [
    "## How can we find the most commonly used word?\n",
    "\n",
    "One guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1db395d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msentence_df\u001b[49m\u001b[38;5;241m.\u001b[39mmax()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence_df' is not defined"
     ]
    }
   ],
   "source": [
    "sentence_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57c599",
   "metadata": {},
   "source": [
    "This is the maximum number of times each word appears in single \"document\", but it's also not sorted, it's alphabetical.\n",
    "\n",
    "This shows the word that appears the most times.\n",
    "\n",
    "\n",
    "To get what we want we need to sum, which by default is along the columns, or per word. Then we get the location of the max with idx max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59df0797",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msentence_df\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39midxmax()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence_df' is not defined"
     ]
    }
   ],
   "source": [
    "sentence_df.sum().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2cd426",
   "metadata": {},
   "source": [
    "## Distances in text\n",
    "We can now use a distance function to calculate how far apart the different sentences are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaa7b058",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m euclidean_distances(\u001b[43msentence_df\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence_df' is not defined"
     ]
    }
   ],
   "source": [
    "euclidean_distances(sentence_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a24aa",
   "metadata": {},
   "source": [
    "This distance is only int terms of actual reused words.  It does not contain anything about the meaning of the words\n",
    "\n",
    "\n",
    "We can make this eaiser to read by making it a Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a006c91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dist_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39meuclidean_distances(\u001b[43msentence_df\u001b[49m),index \u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattribution\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      2\u001b[0m                       columns\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattribution\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence_df' is not defined"
     ]
    }
   ],
   "source": [
    "dist_df = pd.DataFrame(data=euclidean_distances(sentence_df),index =df['attribution'],\n",
    "                      columns=df['attribution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa5ea64b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdist_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist_df' is not defined"
     ]
    }
   ],
   "source": [
    "dist_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd11900",
   "metadata": {},
   "source": [
    "Who wrote the most similar question to me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3255ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdist_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Dr. Brown\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Dr. Brown\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39midxmin()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist_df' is not defined"
     ]
    }
   ],
   "source": [
    "dist_df[' Dr. Brown'].drop(' Dr. Brown').idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134b303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3933805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcbe440e",
   "metadata": {},
   "source": [
    "## Check on Your grade:  \n",
    "\n",
    "\n",
    "```\n",
    "grade_in = pd.read_json('grade-tracker-2022-11-18.json')\n",
    "skill_level = grade_in['title'].str.split('-').apply(pd.Series).rename(columns={0:'skill',1:'level'})\n",
    "grade_df_tall = pd.concat([grade_in['state'],skill_level],axis=1)\n",
    "grade_df_view = grade_df_tall.pivot(index='skill',columns ='level').replace({'OPEN':'','CLOSED':'achieved'}\n",
    "\n",
    "grade_df_num = grade_df_tall.pivot(index='skill',columns ='level').replace({'OPEN':0,'CLOSED':1})\n",
    "```\n",
    "\n",
    "Then you can use summary statistics to get the number of achivements you have already earned at each level.  \n",
    "\n",
    "```{important}\n",
    "Remember if your grade is lower than you want right now, this is the **minimum** grade you can earn, your grade can go up and you are not likely locked out of the grade you want.  Use office hours to make up level 1.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Questions After Classroom\n",
    "\n",
    "### How can this be used for training a classifier?\n",
    "\n",
    "To train a classifier, we would also need target variables, but the `mat` variable we had above can be used as the `X` for any `sklearn` estimator object.\n",
    "To train more complex tasks you would need appropriate data: for example labeled articles that are real and fake to train a fake news classifier (this is provided for a12)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "source_map": [
   12,
   28,
   43,
   47,
   49,
   53,
   56,
   63,
   69,
   92,
   99,
   102,
   106,
   110,
   113,
   138,
   141,
   146,
   148,
   151,
   153,
   159,
   161,
   166,
   169,
   182,
   184,
   191,
   195,
   197,
   205,
   208,
   213,
   215,
   222,
   224,
   230,
   232,
   238,
   243,
   245,
   249,
   253,
   257,
   259
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}