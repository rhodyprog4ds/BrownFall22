{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82179b2",
   "metadata": {},
   "source": [
    "# Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd79d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import cluster\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "# import the whole model selection module\n",
    "from sklearn import model_selection\n",
    "sns.set_theme(palette='colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f057d",
   "metadata": {},
   "source": [
    "## Digits Dataset\n",
    "Today, we'll load a new dataset and use the default sklearn data structure for datasets.  We get back the default data stucture when we use a `load_` function without any parameters at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e4a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc8330",
   "metadata": {},
   "source": [
    "This shows us that the type is defined by sklearn and they called it `bunch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7c1c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5acdec",
   "metadata": {},
   "source": [
    "We can print it out to begin exploring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56dba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee767bd",
   "metadata": {},
   "source": [
    "We note that it has key value pairs, and that the last one is called `DESCR` and is text that describes the data.  If we send that to the print function it will be formatted more readably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bf70d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79541571",
   "metadata": {},
   "source": [
    "This tells us that we are going to be predicting what digit (0,1,2,3,4,5,6,7,8, or 9) is in the image.\n",
    "\n",
    "To get an idea of what the images look like, we can use `matshow` which is short for matrix show. It takes a 2D matrix and plots it as a grayscale image. To get the actual color bar, we use the matplotlib `plt.gray()`.  \n",
    "````{margin}\n",
    "```{admonition} Try it yourself\n",
    "Try using matshow without `plt.gray()`. How is it different?  What might alternatives do?  What other code in this notebook influences how plots look?\n",
    "```\n",
    "```{tip}\n",
    "Removing a line from an excerpt of code can help you see hat that line did and learn more about how each piece work.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c1f980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb849dc4b80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAGsCAYAAADtzsGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAksUlEQVR4nO3de3BU9f3/8deGkBgJScCJzIRYIyhZwi0RxpQiiEBHqVAyY+3EtOAdbEERpSN2FIapM1C/yqgoWFQUW4M6ijZSYFTQaNGxA4QoyEIIEy5SmIwsIQtLrvv7g19SIiA5m/P5bHbzfMw4p9nsvs67y8l5cc4ecjyhUCgkAAAsiYv0AACAroXiAQBYRfEAAKyieAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsComi6eyslJ33XWXcnNzNWrUKD311FOqr6+P9Fjtsn//fs2fP19TpkxRTk6OJk2aFOmR2mX9+vX6wx/+oDFjxig3N1dTpkzRu+++q87+izFKS0v1+9//Xj//+c81ePBgjR8/XosWLVJtbW2kR3Pk5MmTGjNmjLKzs/Xtt99GepyftGbNGmVnZ5/z39NPPx3p0drl/fffV0FBgYYMGaL8/Hzde++9On36dKTH+klTp04973uenZ2tf/3rX9bnibe+RsNqamp0xx13KCsrS0uXLtXRo0e1ePFinT59WvPnz4/0eBdVUVGh0tJSDRs2TM3NzZ1+x93i9ddfV9++fTVv3jz16tVLX375pZ544gkdOXJEs2bNivR4F3T8+HENHTpUU6dOVVpamioqKrR06VJVVFRo5cqVkR6v3ZYtW6ampqZIj+HIK6+8op49e7Z+3adPnwhO0z7Lly/Xyy+/rPvvv1+5ubny+/366quvOv17v2DBAgUCgTaPrVq1Sh999JFGjhxpf6BQjHnppZdCubm5Ib/f3/rYW2+9FRo4cGDoyJEjkRusnZqamlr/96OPPhq65ZZbIjhN+/3www/nPPb444+Hrr322jb/n6LB22+/HRowYEBUbC+hUCi0d+/eUG5ubmj16tWhAQMGhL755ptIj/ST3nvvvdCAAQPOu810ZpWVlaGcnJzQZ599FulRXDFu3LjQfffdF5F1x9ypts8//1wjR45UWlpa62MTJ05Uc3OzNm/eHLnB2ikuLjr/SHr37n3OYwMHDlQgENCpU6ciMFH4WradhoaGyA7STk8++aQKCwt11VVXRXqUmLZmzRplZmbqhhtuiPQoHbZt2zYdOnRIkydPjsj6o3Mv9xP27dunfv36tXksJSVF6enp2rdvX4Sm6pq2bt2qPn36KDk5OdKjXFRTU5Pq6uq0c+dOvfjiixo3bpwyMzMjPdZFbdiwQXv27NHMmTMjPYpjkyZN0sCBAzV+/Hj97W9/6/Snq8rLyzVgwAAtW7ZMI0eO1ODBg1VYWKjy8vJIj+bY2rVrdemll2r8+PERWX/MfcZz4sQJpaSknPN4amqqampqIjBR17RlyxatW7dOjz76aKRHaZcbb7xRR48elSSNHj1azzzzTIQnurhgMKjFixdrzpw5UVHuLdLT0/XAAw9o2LBh8ng82rRpk5599lkdPXq0U38OW11drR07dmjPnj1asGCBkpKS9NJLL+nuu+/WRx99pMsuuyzSI7ZLY2Oj1q9fr3HjxunSSy+NyAwxVzyIvCNHjmjOnDnKz8/XtGnTIj1Ou6xYsULBYFB79+7V8uXLdf/99+u1115Tt27dIj3aBS1fvlyXXXaZbr311kiP4sjo0aM1evTo1q+vv/56JSYmatWqVbr//vt1+eWXR3C6CwuFQjp16pSee+45eb1eSdKwYcM0btw4/eMf/9Ds2bMjPGH7bN68WceOHYvoFbMxd6otJSXlvJfC1tTUKDU1NQITdS0nTpzQfffdp7S0NC1dujRqPrPyer3Ky8vTbbfdpmXLlunrr7/Wxx9/HOmxLuj777/XypUr9eCDD6q2tlYnTpxo/Szt1KlTOnnyZIQndGbixIlqamrSrl27Ij3KBaWkpCgtLa21dKQznwfm5ORo7969EZzMmbVr1yotLU3XX399xGaIuSOefv36nfNZTm1traqrq8/57AfuOn36tGbMmKHa2lq9/fbbbS6VjSbZ2dnq3r27Dhw4EOlRLujQoUNqaGjQ9OnTz/netGnTNGzYML3zzjsRmCx2XX311RfcJurq6ixPE57Tp0/rk08+0a9//Wt17949YnPEXPGMGTNGL730UpvPejZs2KC4uDiNGjUqwtPFrsbGRj300EPat2+f3nzzzaj4NxkXUl5eroaGhk59ccHAgQP1xhtvtHls165dWrRokRYuXKghQ4ZEaLLwrFu3Tt26dVNOTk6kR7mgG2+8UWvWrNGuXbs0cOBASZLf79fOnTt15513Rna4dtq0aZNOnToVsavZWsRc8RQWFurvf/+7Zs6cqRkzZujo0aN66qmnVFhYGBU7w2AwqNLSUklnTqcEAgFt2LBBknTddded97LlzmDhwoX69NNPNW/ePAUCAW3fvr31ezk5OUpISIjccD9h1qxZGjx4sLKzs3XJJZfI5/Pp1VdfVXZ2tiZMmBDp8S4oJSVF+fn55/3eoEGDNGjQIMsTtd8999yj/Px8ZWdnS5I2btyod955R9OmTVN6enqEp7uwCRMmaMiQIXrwwQc1Z84cJSYmasWKFUpISFBRUVGkx2uXDz/8UBkZGRo+fHhE5/CEQlHyT+MdqKys1F/+8heVlZWpR48emjJliubMmdNpd35nO3To0AUvcXzjjTcuuLOJtHHjxun7778/7/c2btzYaY8eVqxYoXXr1unAgQMKhULq27evfvnLX+qee+6JqivFJOnrr7/WtGnT9O6773bqI54nn3xSX3zxhY4cOaLm5mZlZWXptttu09SpU+XxeCI93k86duyYFi1apE8//VQNDQ0aMWKEHnvsMV199dWRHu2iampqNGrUKN1xxx3605/+FNFZYrJ4AACdV3RccgQAiBkUDwDAKooHAGAVxQMAsIriAQBYRfEAAKyieAAAVsV08YwfPz5i95voqGidPVrnlqJ39midW4re2aN1bqlzzB7TxQMA6HwoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFgV07dFOHz4sCQpIyMjwpM4F62zR+vcUvTOHq1zS9E7e7TOLXWO2TtF8TQ0NOjgwYOu58bHx+uKK67QwYMH1djY6Hq+SaZnN3U3Vo/Ho6SkJAWDQZnYtOLizB2kezweJSYmqq6uzsjs//3vf13PlNjOIyFa55bMzn7FFVeoe/fuF31epyieffv2qX///q7n5uXladu2bbr22mtVVlbmer5Jpmf/4IMPXM+UpNTUVI0dO1afffaZampqXM9PS0tzPbNFcnKyhg8frq1btyoQCLieP3bsWNczJbbzSIjWuSWzs1dWVqpfv34XfR6f8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwynHxVFZW6q677lJubq5GjRqlp556SvX19SZmAwDEoHgnT66pqdEdd9yhrKwsLV26VEePHtXixYt1+vRpzZ8/39SMAIAY4qh43nrrLZ08eVIvvPBC650gm5qatHDhQs2YMcPY7ZQBALHD0am2zz//XCNHjmxz++GJEyequblZmzdvdns2AEAMclQ8+/btO+d+2ikpKUpPT9e+fftcHQwAEJscnWo7ceKEUlJSznk8NTVVNTU14Q8RH6+8vLywX38hXq+3zTKamJ49NTXVSG5ycnKbpal8E5KSktos3WZiG5fYziMhWueWzM6ekJDQrud5QqFQqL2hgwYN0uzZszV9+vQ2j0+aNEl5eXn6y1/+4mzK/y8UCsnj8YT1WgBAdHF0xJOSkqLa2tpzHq+pqenQ36APHjyogoKCsF9/IV6vV8XFxSoqKpLP53M93yTTsy9ZssT1TOnMEcmIESO0ZcsWBQIB1/N79uzpemaLpKQk5eTk6LvvvlMwGHQ9/7777nM9U2I7j4RonVsyO3tJSYkyMzMv+jxHxdOvX79zPsupra1VdXX1OZ/9ONHY2KiysrKwX38xPp/PaL5JpmbvyKnR9ggEAkbWYePIOBgMGilN09sg27l90Tq3ZGb29v6bTkcXF4wZM0ZffvmlTpw40frYhg0bFBcXp1GjRjmbEADQJTkqnsLCQvXo0UMzZ87Uv//9b7333nt66qmnVFhYyL/hAQC0i6PiSU1N1apVq9StWzfNnDlTzzzzjH7zm99o3rx5puYDAMQYR5/xSFL//v31+uuvGxgFANAV8NupAQBWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArHJ8Izj8T1ZWlrHsjIyM1qXf73c9f8qUKa5nnm3s2LFG800aPny4kdxQKGQkt8W2bduM5JaXlxvJlaSkpCRJ0ltvvaVgMOh6fm5uruuZ6DiOeAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKyieAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKyieAAAVjm+A+n+/fv16quvqry8XBUVFerXr5/Wrl1rYjYAQAxyXDwVFRUqLS3VsGHD1NzcbPx2vgCA2OL4VNu4ceNUWlqq559/XoMGDTIxEwAghjkunrg4PhYCAITP8ak2E+Lj45WXl+d6rtfrbbN0W0ZGhpFcSerfv3+bJRApSUlJxrITExPbLN1mYr8imd+3mGRy9oSEhHY9zxPqwIc08+bN044dOzp8cUEoFJLH4+lQBgAgOnSKI56DBw+qoKDA9Vyv16vi4mIVFRXJ5/O5nm/6iOe5557T7NmzVVlZ6Xo+VyKivfbs2WMsOzExUVdeeaX279+vuro61/MLCwtdz5TM71tMMjl7SUmJMjMzL/q8TlE8jY2NKisrM5bv8/mM5Pv9ftczf6yyslI7d+40vh7gQoLBoPF11NXVGVmPyf2KZG7fYoOJ2evr69v1PK4UAABYRfEAAKxyfKotGAyqtLRUkvT9998rEAhow4YNkqTrrrtOvXv3dndCAEBMcVw8P/zwg2bPnt3msZav33jjDeXn57szGQAgJjkunszMTO3evdvELACALoDPeAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKyieAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKxyfCM4/E9aWpqx7J49e7YuTa4n2rTcdt2E5ORkDR8+XFu3blUgEHA9v6qqyvVMSerdu7cmT56sDz/8UMeOHXM9f+zYsa5ntkhISJB0ZjtPTEw0th50LhzxAACsongAAFZRPAAAqygeAIBVFA8AwCqKBwBgFcUDALCK4gEAWEXxAACsongAAFZRPAAAqygeAIBVFA8AwCqKBwBgFcUDALCK4gEAWOXoRnDr169XSUmJdu7cqRMnTujKK6/U1KlTdeutt8rj8ZiaEQAQQxwVz+uvv66+fftq3rx56tWrl7788ks98cQTOnLkiGbNmmVqRgBADHFUPMuXL1fv3r1bvx45cqSOHz+u1157TX/84x8VF8eZOwDAT3PUFGeXTouBAwcqEAjo1KlTrg0FAIhdHT5E2bp1q/r06aPk5GQ35gEAxDhHp9p+bMuWLVq3bp0effTRjg0RH6+8vLwOZZyP1+tts3Rbdna2kVxJysrKarPEGSb/gpOUlNRm6bbznTFwQ2pqapul2xISEozkSmd+9s9eus3EfkUyv28xyeTs7d1WPKFQKBTOCo4cOaLbbrtN/fv318qVKzv0+U4oFOKqOADoIsIqnhMnTuh3v/udJKm4uFg9e/bs0BAHDhxQQUFBhzLOx+v1qri4WEVFRfL5fK7nmz7iWbRokR577DFVVVW5nr969WrXM23YunWrseykpCTl5OTou+++UzAYdD3/8OHDrmdKZ450xowZo88//1w1NTWu548YMcL1zBbx8fFKT09XdXW1GhsbXc+/5ZZbXM+UzO9bTDI5e0lJiTIzMy/6PMfHt6dPn9aMGTNUW1urt99+u8OlI0mNjY0qKyvrcM6F+Hw+I/lhHiw6UlVVFXUbtkmBQMD4OoLBoJH1HDt2zPXMs9XU1BhZR319veuZP9bY2GhkPSb3K5K5fYsNJmZv75+ho+JpbGzUQw89pH379unNN99Unz59whoOANB1OSqehQsX6tNPP9W8efMUCAS0ffv21u/l5OQY/RASABAbHBXP5s2bJUmLFy8+53sbN25s17k9AEDX5qh4Nm3aZGoOAEAXwe+4AQBYRfEAAKyieAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKyieAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsMrRjeDQVlVVlbHslJQUSdLhw4eNrifaFBQUGMseOnSoSktL9fDDD+ubb75xPf+DDz5wPVOSkpOTJUkZGRmt242b0tLSXM9sERd35u++ycnJam5uNrYedC4c8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArHJ0B9LS0lK9/PLL2rt3rwKBgPr06aMJEyZo1qxZ6tmzp6kZAQAxxFHxHD9+XEOHDtXUqVOVlpamiooKLV26VBUVFVq5cqWpGQEAMcRR8UyZMqXN1/n5+UpISNATTzyho0ePqk+fPq4OBwCIPR3+jCctLU2S1NDQ0NEoAEAX4OiIp0VTU5MaGxu1d+9evfjiixo3bpwyMzPDHyI+Xnl5eWG//kK8Xm+bpdtMfq51zTXXtFnijKFDhxrLNv2eJycnG8lNSkpqs3RbXJy5a5Bask2tw8R+RTK/bzHJ5OwJCQntep4nFAqFnIaPGTNGR48elSSNHj1azz//vC699FKnMa1CoZA8Hk/YrwcARI+wisfn8ykYDGrv3r1avny5MjMz9dprr6lbt25hDXHgwAEVFBSE9dqf4vV6VVxcrKKiIvl8PtfzTR/xvPLKK7r33ntVUVHhen5paanrmTbccMMNxrJNv+dLlixxPVM6c6STk5Oj7777TsFg0PX8AQMGuJ7ZIi4uTj169NDJkyfV3Nzser6p7cX0vsUkk7OXlJS06+xXWKfaWg7R8vLyNGTIEE2ZMkUff/yxbr755nDi1NjYqLKysrBe2x4+n89IfsvnWyZVVFTom2++Mb6eaGHjvTD1ngcCAdczzxYMBo2sw0QhnG8dJtZjcr8imdu32GBi9vr6+nY9r8MnVrOzs9W9e3cdOHCgo1EAgC6gw8VTXl6uhoaGDl1cAADoOhydaps1a5YGDx6s7OxsXXLJJfL5fHr11VeVnZ2tCRMmmJoRABBDHBXP0KFDtW7dOq1YsUKhUEh9+/bVbbfdpnvuuafdl9EBALo2R8Uzffp0TZ8+3dQsAIAugN9ODQCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYJWjG8GhrePHjxvLrq2tbV2aWE95ebnrmZKUlJSkAQMGaM+ePQoGg67n+/1+1zN/rLS01Ejuc889ZyQ3PT1dw4cP1+7du1VdXe16fm5uruuZtmRlZRnJzcjIaF2a2Carqqpcz+xMOOIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwqkPFc/LkSY0ZM0bZ2dn69ttv3ZoJABDDOlQ8y5YtU1NTk1uzAAC6gLCLp7KyUsXFxXrggQfcnAcAEOPCLp4nn3xShYWFuuqqq9ycBwAQ48Iqng0bNmjPnj2aOXOm2/MAAGJcvNMXBINBLV68WHPmzFFycrI7Q8THKy8vz5Wss3m93jbLaGJ69qSkJCO5iYmJbZb4n/T0dCO5vXr1arN0W1ycuYtfW7JNrWPQoEFGcvv3799m6TZTf5aS2X1LQkJCu57nCYVCISfBS5Ys0ebNm/Xuu+/K4/Ho66+/1rRp0/Tuu+9qyJAhYQ0bCoXk8XjCei0AILo4OuL5/vvvtXLlSr344ouqra2VJJ06dap1efLkSfXo0cPxEAcPHlRBQYHj112M1+tVcXGxioqK5PP5XM83yfTsb731luuZ0pkjnSuvvFL79+9XXV2d6/kDBgxwPdOW4uJiI7m9evXSxIkTtX79evn9ftfzJ0+e7Hpmi7i4OPXo0UMnT55Uc3Oz6/m3336765nSmSOd5557TrNnz1ZlZaXr+YcPH3Y9s4XJfUtJSYkyMzMv+jxHxXPo0CE1NDRo+vTp53xv2rRpGjZsmN555x0nkZKkxsZGlZWVOX5de/l8PqP5JpmaPRgMup55trq6OuPriDbV1dVG8/1+v5F1mCiE863DxHp27tzpeubZKisrjayjqqrK9cwfM7Fvqa+vb9fzHBXPwIED9cYbb7R5bNeuXVq0aJEWLlwY9qk2AEDX4ah4UlJSlJ+ff97vDRo0yNgHeQCA2MHvagMAWOX4cuofy8/P1+7du92YBQDQBXDEAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYFWHbwSH6JSbm2skNy8vT9u2bVNhYaHKyspczzc1tyR5vV6tXr1at99+u3w+n+v527dvdz1TOvOeFxUV6emnnzbynpuUnp6uoqIiffjhh6qurnY9/9lnn3U9U5JSU1MlSXPnzlVNTY3r+QUFBa5ndiYc8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArHJUPGvWrFF2dvY5/z399NOm5gMAxJiwbn39yiuvqGfPnq1f9+nTx7WBAACxLaziGTRokHr37u32LACALoDPeAAAVoV1xDNp0iT5/X5lZGTot7/9re69915169Yt/CHi45WXlxf26y/E6/W2WUaTaJ3d9NzZ2dlGciUpKyurzdJtHo/HSK7p9zw9Pd1IriT16tWrzdJtqampRnKTk5PbLN1mYn/YwuT2kpCQ0K7neUKhUKi9oV988YXKy8s1bNgweTwebdq0SatXr9btt9+u+fPnhz1sKBQy9kMJAOhcHBXP+fz1r3/VqlWr9Nlnn+nyyy8PK+PAgQMqKCjoyBjn5fV6VVxcrKKiIvl8PtfzTYrW2U3PbfqIZ9GiRXrsscdUVVXlev7u3btdz5TMv+dz5851PbNFr169NHHiRK1fv15+v9/1/IyMDNczpTNHOiNGjNCWLVsUCARcz3/44Yddz2xhcnspKSlRZmbmRZ8X1qm2s02cOFErV67Url27wi6exsZGlZWVdXSUC/L5fEbzTYrW2U3N3cG/J7VLVVWVkR349u3bXc88m6n3vLq62vXMH/P7/UbW06NHD9czzxYIBFRTU+N6ro2feRPbS319fbuex8UFAACrOlw869atU7du3ZSTk+PGPACAGOfoVNs999yj/Pz81vPsGzdu1DvvvKNp06YZvfIFABA7HBXPVVddpffee09HjhxRc3OzsrKy9Oc//1lTp041NR8AIMY4Kp7HH3/c1BwAgC6CiwsAAFZRPAAAqygeAIBVFA8AwCqKBwBgFcUDALCK4gEAWEXxAACsongAAFZRPAAAqygeAIBVFA8AwCqKBwBgFcUDALCK4gEAWEXxAACscnQjOCDStm/fbizb4/FIknbv3m1kPc8++6zrmZJabzs/d+5cVVdXu55/5513up7ZIi7uzN99J0+erObmZtfzCwoKXM+UpGuuuUZjx45VcXGxKioqjKwjlnHEAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYBXFAwCwiuIBAFhF8QAArKJ4AABWUTwAAKsoHgCAVRQPAMAqigcAYFVYxfP++++roKBAQ4YMUX5+vu69916dPn3a7dkAADHI8R1Ily9frpdffln333+/cnNz5ff79dVXX6mpqcnEfACAGOOoePbt26cXXnhBy5Yt0w033ND6+E033eT6YACA2OToVNuaNWuUmZnZpnQAAHDCUfGUl5drwIABWrZsmUaOHKnBgwersLBQ5eXlpuYDAMQYR6faqqurtWPHDu3Zs0cLFixQUlKSXnrpJd1999366KOPdNlll4U3RHy88vLywnrtT/F6vW2W0SRaZ4/WuSXzs6enpxvJ7dWrV5ul2+LizF382pJtah3XXHONkdyf/exnbZZuq6mpMZIrmd3OExIS2vU8TygUCrU39KabblJVVZX++c9/tg59/PhxjRs3TnfccYdmz54d1rChUEgejyes1wIAooujI56UlBSlpaW1acq0tDTl5ORo7969YQ9x8OBBFRQUhP36C/F6vSouLlZRUZF8Pp/r+SZF6+zROrdkfva5c+e6nimdOdKZOHGi1q9fL7/f73r+5MmTXc9sERcXpx49eujkyZNqbm52Pf+RRx5xPVM6c6Tz+OOP68knn9SBAwdcz9+yZYvrmS1MbuclJSXKzMy86PMcFc/VV199wTe5rq7OSVQbjY2NKisrC/v1F+Pz+YzmmxSts0fr3JK52aurq13PPJvf7zeyDhOFcL51mFhPRUWF65lnO3DggJF12PjZMbGd19fXt+t5jk6s3njjjTp+/Lh27drV+pjf79fOnTs1aNAgZxMCALokR0c8EyZM0JAhQ/Tggw9qzpw5SkxM1IoVK5SQkKCioiJTMwIAYoijI564uDitWLFCubm5mj9/vh5++GElJyfrzTffNHbFDgAgtjj+lTm9e/fW//3f/5mYBQDQBfDbqQEAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKyieAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKxyfCM4xIZnn33WSG7LnWjnzp2r6upq1/Nzc3Ndz2yRnJwsSXr55ZcVCARcz09LS3M9U5KSkpIkSSNGjFAwGHQ9f+zYsa5ntvB6vVq9erWmT58un8/nev727dtdz5SkmpoaSdKWLVtUVlZmZB2xjCMeAIBVFA8AwCqKBwBgFcUDALCK4gEAWEXxAACsongAAFZRPAAAqygeAIBVFA8AwCqKBwBgFcUDALCK4gEAWEXxAACsongAAFZRPAAAqygeAIBVju5AOnXqVP3nP/857/eWLFmiW265xZWhAACxy1HxLFiw4JxbAq9atUofffSRRo4c6epgAIDY5Kh4rr766nMee+SRRzRq1Cj17t3btaEAALGrQ5/xbNu2TYcOHdLkyZPdmgcAEOMcHfH82Nq1a3XppZdq/PjxHRsiPl55eXkdyjgfr9fbZhlNTM+enp5uJLdXr15tlm5LTk42kitJSUlJbZam8t2WmJjYZuk2kz8/WVlZbZZu83g8RnLZt5xfQkJCu57nCYVCoXBW0NjYqNGjR+sXv/iFnnnmmXAiWoVCIWMbCACgcwn7iGfz5s06duyYJk2a1OEhDh48qIKCgg7n/JjX61VxcbGKiork8/lczzfJ9Oxz5851PVM6c6QzceJErV+/Xn6/3/X87Oxs1zNbJCUlKScnR999952CwaDr+T179nQ9UzpzpHPllVdq//79qqurcz1/wYIFrme2yMrK0qJFi/TYY4+pqqrK9fzdu3e7nimxb7mQkpISZWZmXvR5YRfP2rVrlZaWpuuvvz7ciFaNjY0qKyvrcM6F+Hw+o/kmmZq9urra9cyz+f1+I+vo27ev65k/FgwGz7l60w3x8R06s31RdXV1RgrTxo61qqrKyHq2b9/ueubZ2Le0VV9f367nhXVxwenTp/XJJ5/o5ptvVvfu3cOJAAB0UWEVz6ZNm3Tq1CmuZgMAOBZW8Xz44YfKyMjQ8OHD3Z4HABDjHBdPTU2NvvjiC/3qV7/iSjQAgGOOP+1MTU3Vjh07TMwCAOgC+O3UAACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKyieAAAVlE8AACrKB4AgFUUDwDAKooHAGAVxQMAsIriAQBYRfEAAKzyhEKhUKSHaGho0MGDB13PTUhIUGZmpg4dOqT6+nrX800yPftll13meqYkdevWTcnJyQoEAmpqanI9PyEhwfXMFnFxcUpMTFRdXZ2am5uN5Jvg8XiUkJCg+vp6mfhxrq6udj2zRffu3dWnTx8dPXpUDQ0Nrueb+rln33J+V1xxhbp3737R53WK4jHl8OHDkqSMjIwIT+JctM4erXNL0Tt7tM4tRe/s0Tq31Dlmj+niGT9+vCRp48aNEZ7EuWidPVrnlqJ39midW4re2aN1bqlzzM5nPAAAqygeAIBVFA8AwCqKBwBgFcUDALCK4gEAWBXTl1MDADofjngAAFZRPAAAqygeAIBVFA8AwCqKBwBgFcUDALCK4gEAWEXxAACsongAAFb9P2ALPgbLTlYbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/runner/work/BrownFall22/BrownFall22/_build/jupyter_execute/notes/2022-11-18_11_2.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697cbab2",
   "metadata": {},
   "source": [
    "## Setting up the Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef441ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_X = digits.data\n",
    "digits_y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9816d",
   "metadata": {},
   "source": [
    "`bunch` objects are designed for machine learning, so they have the features as \"data\" and target explicitly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5029534e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_X.shape, digits_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96931b",
   "metadata": {},
   "source": [
    "This has one row for each sample and has reshaped the 8x8 image into a 64 length vector. So we have one 'feature' for each pixel in the images.\n",
    "\n",
    "\n",
    "\n",
    "The size of the `.images` is the total number of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27e890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1797*8*8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f0c2b",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "\n",
    "We are going to do some model comparison, so we will instantiate estimator objects for two different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5aa2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC(gamma=0.001)\n",
    "gnb_clf = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5ebb4",
   "metadata": {},
   "source": [
    "We're going to use a [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) object to do Cross validation with 100 iterations to get smoother mean test and train\n",
    "score curves, each time with 20% data randomly selected as a validation set.\n",
    "\n",
    "```{admonition} Further Reading\n",
    "\n",
    "You can see visualization of different [cross validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#visualize-cross-validation-indices-for-many-cv-objects) types in the sklearn documentation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc951d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f50a5",
   "metadata": {},
   "source": [
    "```{note}\n",
    "This object has a `random_state` object, the `GridSearchCV` that we were using didn't have a way to control the random state directly, but it accepts not only integers, but also cross validation objects to the `cv` parameter. The KFold cross validation object also has that parameter, so we could repeat what we did in previous classes by creating a `KFold` object with a fixed random state.\n",
    "```\n",
    "\n",
    "We'll also create a linearly spaced list of training percentages.\n",
    "\n",
    "```{important}\n",
    "You could speed it up by splitting it into jobs with the `n_jobs` parameter\n",
    "```\n",
    "\n",
    "````{margin}\n",
    "```{admonition} Try it yourself\n",
    "Try varying the `n_jobs` parameter and tmiing the execution using the\n",
    "[timit magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit)\n",
    "```\n",
    "````\n",
    "Now we can create the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24966d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m.05\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m train_sizes_svm, train_scores_svm, test_scores_svm, fit_times_svm, score_times_svm \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdigits_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdigits_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1558\u001b[0m, in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[1;32m   1556\u001b[0m         train_test_proportions\u001b[38;5;241m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[0;32m-> 1558\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_test_proportions\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m results \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(results)\n\u001b[1;32m   1576\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_unique_ticks)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    705\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    707\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 708\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:429\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_passthrough_scorer\u001b[39m(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;124;03m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/base.py:666\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/svm/_base.py:810\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    808\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/svm/_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    434\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/svm/_base.py:454\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be equal to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of samples at training time\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m             \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    452\u001b[0m svm_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sizes = np.linspace(.05,1,10)\n",
    "\n",
    "train_sizes_svm, train_scores_svm, test_scores_svm, fit_times_svm, score_times_svm = model_selection.learning_curve(\n",
    "    svm_clf,\n",
    "    digits_X,\n",
    "    digits_y,\n",
    "    cv=cv,\n",
    "    train_sizes=train_sizes,\n",
    "    return_times=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b947456",
   "metadata": {},
   "source": [
    "It returns the list of the counts for each training size (we input percentages and it returns counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1127daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3bd7b7",
   "metadata": {},
   "source": [
    "The other parameters, it returns a list for each length that's 100 long because our cross validation was 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa0334",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_times_svm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df22ff3",
   "metadata": {},
   "source": [
    "We can save it in a DataFrame after averaging over the 100 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_learning_df = pd.DataFrame(data = train_sizes_svm, columns = ['train_size'])\n",
    "# svm_learning_df['train_size'] = train_sizes_svm\n",
    "svm_learning_df['train_score'] = np.mean(train_scores_svm,axis=1)\n",
    "svm_learning_df['test_score'] = np.mean(test_scores_svm,axis=1)\n",
    "svm_learning_df['fit_time'] = np.mean(fit_times_svm,axis=1)\n",
    "svm_learning_df['score_times'] = np.mean(score_times_svm,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b05272",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_learning_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d19d1",
   "metadata": {},
   "source": [
    "We can use our skills in transforming data to make it easier to exmine just a subset of the scores.\n",
    "````{margin}\n",
    "```{hint}\n",
    "This is *one* thing we can analyze, but there are others. To earn prepare on assignment 11,  manipulate your results a different way.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_learning_df_scores = svm_learning_df.melt(id_vars=['train_size'],\n",
    "                                                value_vars=['train_score','test_score'])\n",
    "svm_learning_df_scores.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216d647",
   "metadata": {},
   "source": [
    "This new DataFrame allows us to make convenient plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=svm_learning_df_scores,x='train_size',y='value',hue='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f123f3c",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "We can do the same thing with GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f28f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_gnb, train_scores_gnb, test_scores_gnb, fit_times_gnb, score_times_gnb = model_selection.learning_curve(\n",
    "  gnb_clf,\n",
    "  digits_X,\n",
    "  digits_y,\n",
    "  cv=cv,\n",
    "  train_sizes=train_sizes,\n",
    "  return_times=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4313c4",
   "metadata": {},
   "source": [
    "````{margin}\n",
    "```{tip}\n",
    "Getting used to thinking though these sorts of manipulations can take time, but\n",
    "is valuable. Investing time to learn these things will help you both write\n",
    "shorter, more readable, easy to examine, code (which is nicer to your co-workers)\n",
    "and help you develop flexible mental representation.  The flexiblity of your\n",
    "mental model of material is the way learning scientists distinguish compentent\n",
    "practioners from experts.  \n",
    "\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18510324",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_learning_df = pd.DataFrame(data = train_sizes_gnb, columns = ['train_size'])\n",
    "# gnb_learning_df['train_size'] = train_sizes_gnb\n",
    "gnb_learning_df['train_score'] = np.mean(train_scores_gnb,axis=1)\n",
    "gnb_learning_df['test_score'] = np.mean(test_scores_gnb,axis=1)\n",
    "gnb_learning_df['fit_time'] = np.mean(fit_times_gnb,axis=1)\n",
    "gnb_learning_df['score_times_gnb'] = np.mean(score_times_gnb,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc91399",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_learning_scores = gnb_learning_df.melt(id_vars=['train_size'],value_vars=['train_score','test_score'])\n",
    "sns.lineplot(data = gnb_learning_scores, x ='train_size', y='value',hue='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08d8c1",
   "metadata": {},
   "source": [
    "Notice in this case that the training accuracy starts high with the test accuracy low.  This big gap means that the model was overfitting to something that was different about the training set from the test set.  It was \n",
    "\n",
    "## Questions After Class\n",
    "\n",
    "### how do I run the code to pull issues?\n",
    "\n",
    "This uses the [GitHub CLI](https://cli.github.com/)\n",
    "\n",
    "```\n",
    "gh issue list --state all -L 45 --json title,url,state > grade-tracker.json\n",
    "```\n",
    "\n",
    "### Is fit time as important as accuracy? I would think generally for real life application we would want results over time.\n",
    "\n",
    "Fit time is generally not as important as accuracy when deploying a model. This question gets at a really important point.  Some of the metrics that we have for machine learning algorithms are for evaluating the *learning* algorithm, if someone develops a new learning algorithm that can perform as well as old ones, but faster that's really helpful.  You are correct,  \n",
    "\n",
    "That said, the score time can be really important in a deployed model.\n",
    "\n",
    "### Why in the SVC model did we used gamma=0.001 and not other values? Why does that parameter represent in the model?\n",
    "\n",
    "The gamma $\\gamma$ parameter for the default rbf kernel controls basically how wavy the line is.  I set it to a value that is known to work well for this dataset because, for time reasons, I did not want to also do a grid search.\n",
    "\n",
    "### I'm sure it will be in the notes but a better understanding of how learning curve works\n",
    "\n",
    "### Can you go over the melt function again?\n",
    "\n",
    " running code will be posted tonight correct?\n",
    "\n",
    " nothing at the moment"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "source_map": [
   12,
   16,
   30,
   36,
   38,
   41,
   43,
   47,
   49,
   52,
   54,
   68,
   71,
   77,
   80,
   85,
   87,
   94,
   96,
   103,
   106,
   116,
   119,
   139,
   149,
   152,
   154,
   157,
   159,
   163,
   172,
   174,
   183,
   187,
   191,
   193,
   199,
   207,
   222,
   231,
   234
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}