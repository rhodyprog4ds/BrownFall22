{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ffcfb8",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "\n",
    "We started thinking about machine learning wiht the idea that the basic idea is\n",
    "that we assume that our target variable ($y_i$) is related to the features $\\mathbf{x}_i$\n",
    "by some function (for sample $i$):\n",
    "\n",
    "$$ y_i =f(\\mathbf{x}_i)$$\n",
    "\n",
    "But we don't know that function exactly, so we assume a type (a decision\n",
    "  tree, a boundary for SVM, a probability distribution) that has some parameters\n",
    "  $\\theta$ and then use a machine\n",
    "  learning algorithm $\\mathcal{A}$ to estimate the parameters for $f$.  In the\n",
    "  decision tree the parameters are the thresholds to compare to, in the GaussianNB the parameters are the mean and variance, in SVM it's the support vectors that define the margin.  \n",
    "\n",
    "$$\\theta = \\mathcal{A}(X,y) $$\n",
    "\n",
    "That we can use to test on our test data:\n",
    "\n",
    "$$ \\hat{y}_i = f(x_i;\\theta) $$\n",
    "\n",
    "A neural net allows us to not assume a specific form for $f$ first, it does\n",
    "universal function approximation.  For one hidden layer and a binary classification problem:\n",
    "\n",
    "\n",
    "$$f(x) = W_2g(W_1^T x +b_1) + b_2 $$\n",
    "\n",
    "where the function $g$ is called the activation function. so we approximate some\n",
    "unknown, complicated function $f4 by taking a weighted sum of all of the inputs,\n",
    "and passing those through another, known function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc44458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ba1df",
   "metadata": {},
   "source": [
    "We're going to use the digits dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b906c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits_X = digits.data\n",
    "digits_y = digits.target\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(digits_X,digits_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c1237e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37f63a",
   "metadata": {},
   "source": [
    "Sklearn provides an estimator for the Multi-Llayer Perceptron (MLP). We can see one with one layer to\n",
    "start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246371e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "  hidden_layer_sizes=(16),\n",
    "  max_iter=100,\n",
    "  alpha=1e-4,\n",
    "  solver=\"lbfgs\",\n",
    "  verbose=10,\n",
    "  random_state=1,\n",
    "  learning_rate_init=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca6f765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =         1210     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.21925D+00    |proj g|=  7.00278D+00\n",
      "\n",
      "At iterate    1    f=  8.16567D+00    |proj g|=  7.22122D+00\n",
      "\n",
      "At iterate    2    f=  3.16228D+00    |proj g|=  1.95656D+00\n",
      "\n",
      "At iterate    3    f=  2.36620D+00    |proj g|=  3.94812D-01\n",
      "\n",
      "At iterate    4    f=  2.25501D+00    |proj g|=  2.35379D-01\n",
      "\n",
      "At iterate    5    f=  2.12211D+00    |proj g|=  2.92144D-01\n",
      "\n",
      "At iterate    6    f=  1.97474D+00    |proj g|=  3.52230D-01\n",
      "\n",
      "At iterate    7    f=  1.71572D+00    |proj g|=  3.81059D-01\n",
      "\n",
      "At iterate    8    f=  1.55334D+00    |proj g|=  5.65391D-01\n",
      "\n",
      "At iterate    9    f=  1.49638D+00    |proj g|=  3.19177D-01\n",
      "\n",
      "At iterate   10    f=  1.42795D+00    |proj g|=  2.96076D-01\n",
      "\n",
      "At iterate   11    f=  1.31674D+00    |proj g|=  2.97448D-01\n",
      "\n",
      "At iterate   12    f=  1.18559D+00    |proj g|=  3.85525D-01\n",
      "\n",
      "At iterate   13    f=  1.11287D+00    |proj g|=  7.99083D-01\n",
      "\n",
      "At iterate   14    f=  1.04537D+00    |proj g|=  1.88585D-01\n",
      "\n",
      "At iterate   15    f=  1.01329D+00    |proj g|=  1.99620D-01\n",
      "\n",
      "At iterate   16    f=  9.53658D-01    |proj g|=  2.66325D-01\n",
      "\n",
      "At iterate   17    f=  9.35570D-01    |proj g|=  9.67258D-01\n",
      "\n",
      "At iterate   18    f=  8.80148D-01    |proj g|=  4.82901D-01\n",
      "\n",
      "At iterate   19    f=  8.58957D-01    |proj g|=  2.67480D-01\n",
      "\n",
      "At iterate   20    f=  8.28073D-01    |proj g|=  2.27267D-01\n",
      "\n",
      "At iterate   21    f=  7.85066D-01    |proj g|=  1.51837D-01\n",
      "\n",
      "At iterate   22    f=  7.33833D-01    |proj g|=  4.17359D-01\n",
      "\n",
      "At iterate   23    f=  6.62096D-01    |proj g|=  2.80666D-01\n",
      "\n",
      "At iterate   24    f=  6.22671D-01    |proj g|=  1.55118D-01\n",
      "\n",
      "At iterate   25    f=  5.83785D-01    |proj g|=  3.74732D-01\n",
      "\n",
      "At iterate   26    f=  5.60433D-01    |proj g|=  1.92151D-01\n",
      "\n",
      "At iterate   27    f=  5.36484D-01    |proj g|=  3.89682D-01\n",
      "\n",
      "At iterate   28    f=  4.78129D-01    |proj g|=  6.78135D-01\n",
      "\n",
      "At iterate   29    f=  4.35061D-01    |proj g|=  4.29782D-01\n",
      "\n",
      "At iterate   30    f=  3.84642D-01    |proj g|=  3.35730D-01\n",
      "\n",
      "At iterate   31    f=  3.43653D-01    |proj g|=  6.73670D-01\n",
      "\n",
      "At iterate   32    f=  3.13295D-01    |proj g|=  2.26639D-01\n",
      "\n",
      "At iterate   33    f=  2.89135D-01    |proj g|=  1.73452D-01\n",
      "\n",
      "At iterate   34    f=  2.55814D-01    |proj g|=  1.92675D-01\n",
      "\n",
      "At iterate   35    f=  2.39728D-01    |proj g|=  1.24939D-01\n",
      "\n",
      "At iterate   36    f=  2.29163D-01    |proj g|=  1.57575D-01\n",
      "\n",
      "At iterate   37    f=  2.12515D-01    |proj g|=  1.44845D-01\n",
      "\n",
      "At iterate   38    f=  1.96142D-01    |proj g|=  2.70599D-01\n",
      "\n",
      "At iterate   39    f=  1.77150D-01    |proj g|=  1.09920D-01\n",
      "\n",
      "At iterate   40    f=  1.69804D-01    |proj g|=  7.69681D-02\n",
      "\n",
      "At iterate   41    f=  1.52945D-01    |proj g|=  1.19267D-01\n",
      "\n",
      "At iterate   42    f=  1.45562D-01    |proj g|=  1.30007D-01\n",
      "\n",
      "At iterate   43    f=  1.37365D-01    |proj g|=  4.50491D-02\n",
      "\n",
      "At iterate   44    f=  1.33056D-01    |proj g|=  3.44461D-02\n",
      "\n",
      "At iterate   45    f=  1.27950D-01    |proj g|=  3.56922D-02\n",
      "\n",
      "At iterate   46    f=  1.24212D-01    |proj g|=  2.70621D-01\n",
      "\n",
      "At iterate   47    f=  1.13569D-01    |proj g|=  7.68664D-02\n",
      "\n",
      "At iterate   48    f=  1.06837D-01    |proj g|=  3.47534D-02\n",
      "\n",
      "At iterate   49    f=  1.03010D-01    |proj g|=  4.54721D-02\n",
      "\n",
      "At iterate   50    f=  9.96327D-02    |proj g|=  1.02824D-01\n",
      "\n",
      "At iterate   51    f=  9.41223D-02    |proj g|=  4.42876D-02\n",
      "\n",
      "At iterate   52    f=  8.91933D-02    |proj g|=  3.89652D-02\n",
      "\n",
      "At iterate   53    f=  8.40355D-02    |proj g|=  6.81312D-02\n",
      "\n",
      "At iterate   54    f=  8.06535D-02    |proj g|=  7.22276D-02\n",
      "\n",
      "At iterate   55    f=  7.69370D-02    |proj g|=  4.37708D-02\n",
      "\n",
      "At iterate   56    f=  7.33028D-02    |proj g|=  3.30888D-02\n",
      "\n",
      "At iterate   57    f=  7.00503D-02    |proj g|=  3.28876D-02\n",
      "\n",
      "At iterate   58    f=  6.56914D-02    |proj g|=  6.75003D-02\n",
      "\n",
      "At iterate   59    f=  6.15310D-02    |proj g|=  3.26029D-02\n",
      "\n",
      "At iterate   60    f=  5.86790D-02    |proj g|=  4.19819D-02\n",
      "\n",
      "At iterate   61    f=  5.58096D-02    |proj g|=  3.13297D-02\n",
      "\n",
      "At iterate   62    f=  5.28047D-02    |proj g|=  5.26270D-02\n",
      "\n",
      "At iterate   63    f=  4.88258D-02    |proj g|=  7.10165D-02\n",
      "\n",
      "At iterate   64    f=  4.43120D-02    |proj g|=  3.79245D-02\n",
      "\n",
      "At iterate   65    f=  4.06057D-02    |proj g|=  4.54958D-02\n",
      "\n",
      "At iterate   66    f=  3.85864D-02    |proj g|=  2.83204D-02\n",
      "\n",
      "At iterate   67    f=  3.70383D-02    |proj g|=  3.15955D-02\n",
      "\n",
      "At iterate   68    f=  3.40589D-02    |proj g|=  8.60429D-02\n",
      "\n",
      "At iterate   69    f=  3.06572D-02    |proj g|=  3.67036D-02\n",
      "\n",
      "At iterate   70    f=  2.92022D-02    |proj g|=  1.58565D-02\n",
      "\n",
      "At iterate   71    f=  2.75288D-02    |proj g|=  2.36057D-02\n",
      "\n",
      "At iterate   72    f=  2.60770D-02    |proj g|=  3.11783D-02\n",
      "\n",
      "At iterate   73    f=  2.45529D-02    |proj g|=  1.38772D-02\n",
      "\n",
      "At iterate   74    f=  2.33554D-02    |proj g|=  1.84083D-02\n",
      "\n",
      "At iterate   75    f=  2.22323D-02    |proj g|=  3.27427D-02\n",
      "\n",
      "At iterate   76    f=  2.11953D-02    |proj g|=  3.56292D-02\n",
      "\n",
      "At iterate   77    f=  1.99439D-02    |proj g|=  1.16451D-02\n",
      "\n",
      "At iterate   78    f=  1.91792D-02    |proj g|=  1.47434D-02\n",
      "\n",
      "At iterate   79    f=  1.81569D-02    |proj g|=  1.47259D-02\n",
      "\n",
      "At iterate   80    f=  1.73501D-02    |proj g|=  3.38662D-02\n",
      "\n",
      "At iterate   81    f=  1.63177D-02    |proj g|=  1.14967D-02\n",
      "\n",
      "At iterate   82    f=  1.53945D-02    |proj g|=  8.27146D-03\n",
      "\n",
      "At iterate   83    f=  1.45545D-02    |proj g|=  1.87245D-02\n",
      "\n",
      "At iterate   84    f=  1.37315D-02    |proj g|=  2.39629D-02\n",
      "\n",
      "At iterate   85    f=  1.27995D-02    |proj g|=  9.07698D-03\n",
      "\n",
      "At iterate   86    f=  1.21681D-02    |proj g|=  1.17620D-02\n",
      "\n",
      "At iterate   87    f=  1.16438D-02    |proj g|=  1.27889D-02\n",
      "\n",
      "At iterate   88    f=  1.10019D-02    |proj g|=  1.36326D-02\n",
      "\n",
      "At iterate   89    f=  9.88821D-03    |proj g|=  1.29881D-02\n",
      "\n",
      "At iterate   90    f=  9.13469D-03    |proj g|=  1.69977D-02\n",
      "\n",
      "At iterate   91    f=  8.89800D-03    |proj g|=  3.01583D-02\n",
      "\n",
      "At iterate   92    f=  8.40574D-03    |proj g|=  8.98979D-03\n",
      "\n",
      "At iterate   93    f=  8.14393D-03    |proj g|=  7.82781D-03\n",
      "\n",
      "At iterate   94    f=  7.66767D-03    |proj g|=  1.08729D-02\n",
      "\n",
      "At iterate   95    f=  7.24862D-03    |proj g|=  1.05303D-02\n",
      "\n",
      "At iterate   96    f=  6.91236D-03    |proj g|=  1.05128D-02\n",
      "\n",
      "At iterate   97    f=  6.57109D-03    |proj g|=  6.50697D-03\n",
      "\n",
      "At iterate   98    f=  6.11302D-03    |proj g|=  7.52292D-03\n",
      "\n",
      "At iterate   99    f=  5.90814D-03    |proj g|=  9.73800D-03\n",
      "\n",
      "At iterate  100    f=  5.72466D-03    |proj g|=  3.86670D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      " 1210    100    106      1     0     0   3.867D-03   5.725D-03\n",
      "  F =   5.7246614010212403E-003\n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9288888888888889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3232b7",
   "metadata": {},
   "source": [
    "We can compare it  to SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0241066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911111111111112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = svm.SVC(gamma=0.001)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08ece7",
   "metadata": {},
   "source": [
    "We saw that the SVM performed a bit better, but this is a simple problem.\n",
    "We can also compare these based on much they store, the number of parameters\n",
    "is realted to the complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d5f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c4efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43968"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(list(svm_clf.support_vectors_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4b4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([np.prod(list(c.shape)) for c in mlp.coefs_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fcf9766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.04544792,  0.12067404, -0.27379261, ...,  0.20709889,\n",
       "         -0.25885478,  0.09336685],\n",
       "        [-0.04593881,  0.03009238, -0.19069045, ...,  0.2006957 ,\n",
       "         -0.22772407, -0.17190691],\n",
       "        [ 0.21563462, -0.03506171, -0.14037903, ..., -0.13049391,\n",
       "          0.11532447, -0.08406878],\n",
       "        ...,\n",
       "        [-0.14630541, -0.05092604, -0.23553127, ...,  0.08691572,\n",
       "          0.05896777, -0.07293738],\n",
       "        [ 0.00778229, -0.10123061, -0.07661302, ..., -0.21167286,\n",
       "         -0.29100928, -0.50212262],\n",
       "        [-0.25364507,  0.10567017,  0.04284603, ...,  0.05389517,\n",
       "         -0.04506549, -0.20359177]]),\n",
       " array([[-0.4195524 , -0.0093074 , -0.25021264,  0.43949534,  0.37288252,\n",
       "          0.11959235,  0.45675145, -0.14863813,  0.3823662 , -0.04965362],\n",
       "        [-0.239262  ,  0.43213332,  0.17866601, -0.404468  ,  0.28782924,\n",
       "          0.19171586,  0.10122457,  0.23149726, -0.22656885,  0.10900253],\n",
       "        [ 1.54655759, -0.90875783, -0.7039524 , -0.71434051,  0.55232251,\n",
       "         -0.00974752,  0.36870446, -0.1017839 ,  0.00208007, -0.19532767],\n",
       "        [-0.27703068,  0.43587954, -0.17214133,  0.38500548, -0.10370225,\n",
       "          0.02842182,  0.18492449, -0.02823487,  0.18515368,  0.28898045],\n",
       "        [-0.21108383,  0.3769415 ,  0.06037127, -0.37087844, -0.21702527,\n",
       "          0.06725108, -0.24992151, -0.31979229, -0.33310585,  0.28381626],\n",
       "        [ 0.0974864 ,  0.4444959 , -0.14989573,  0.10000688,  0.09475912,\n",
       "          0.11055364, -0.42394636,  0.23912678,  0.42933942,  0.03239476],\n",
       "        [-0.21977539,  0.85250181, -0.74086368, -0.50390521,  1.01932446,\n",
       "         -0.30844321,  0.87153834,  0.02107133,  0.31516881, -0.39491114],\n",
       "        [-0.4464278 ,  0.02180105,  1.14815854,  0.67666797, -1.47966235,\n",
       "         -0.66735156,  0.02697784, -1.09142481,  0.16178626,  0.07269495],\n",
       "        [-0.3436408 , -0.47289065, -0.52287825,  0.84986976, -0.91673238,\n",
       "          1.60885574,  0.26266081, -0.37507999,  0.00835441, -0.15579539],\n",
       "        [-0.18997893, -0.08028429, -0.23027629,  0.19228202,  0.14524723,\n",
       "         -0.41805562,  0.41693609,  0.27660523,  0.22032044,  0.20108115],\n",
       "        [-0.40909969,  0.1044448 ,  0.09427888,  0.29297614,  0.29256052,\n",
       "          0.06079772, -0.89250146,  1.19196958,  0.04293395, -0.79629869],\n",
       "        [ 0.24847219,  0.25920305,  0.30081189, -0.21607679, -0.32071566,\n",
       "          0.05870636, -0.17941319,  0.26220668,  0.10675355,  0.20740256],\n",
       "        [ 0.11336331, -0.26785745, -0.36164268, -0.14834494, -0.16960451,\n",
       "         -0.19820435,  0.35675418,  0.04240134, -0.09380787, -0.33189044],\n",
       "        [-0.19356802,  0.05330192, -0.24867485, -0.40175324, -0.07917616,\n",
       "          0.25672638, -0.04064918,  0.26758888, -0.00683205,  0.24131156],\n",
       "        [ 0.20642533,  0.11191516, -0.2364608 ,  0.06915919,  0.17356214,\n",
       "         -0.15887618,  0.42856157,  0.33811924, -0.119696  ,  0.11000346],\n",
       "        [ 0.12216544,  0.05823738, -0.42250085, -0.40678659,  0.12000189,\n",
       "         -0.21259095, -0.70513196,  0.08146846,  0.61293926,  1.27110406]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9013a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp64 = MLPClassifier(\n",
    "  hidden_layer_sizes=(64),\n",
    "  max_iter=100,\n",
    "  alpha=1e-4,\n",
    "  solver=\"lbfgs\",\n",
    "  verbose=10,\n",
    "  random_state=1,\n",
    "  learning_rate_init=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc21493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =         4810     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.04315D+01    |proj g|=  8.11718D+00\n",
      "\n",
      "At iterate    1    f=  9.75424D+00    |proj g|=  4.90192D+00\n",
      "\n",
      "At iterate    2    f=  8.69201D+00    |proj g|=  5.11136D+00\n",
      "\n",
      "At iterate    3    f=  7.06707D+00    |proj g|=  3.08950D+00\n",
      "\n",
      "At iterate    4    f=  5.19189D+00    |proj g|=  2.03877D+00\n",
      "\n",
      "At iterate    5    f=  3.57584D+00    |proj g|=  3.71314D+00\n",
      "\n",
      "At iterate    6    f=  2.12478D+00    |proj g|=  1.07366D+00\n",
      "\n",
      "At iterate    7    f=  1.57146D+00    |proj g|=  8.76974D-01\n",
      "\n",
      "At iterate    8    f=  1.08808D+00    |proj g|=  5.25384D-01\n",
      "\n",
      "At iterate    9    f=  8.16400D-01    |proj g|=  3.57840D-01\n",
      "\n",
      "At iterate   10    f=  5.45655D-01    |proj g|=  2.26321D-01\n",
      "\n",
      "At iterate   11    f=  4.22838D-01    |proj g|=  3.20178D-01\n",
      "\n",
      "At iterate   12    f=  3.12334D-01    |proj g|=  1.47141D-01\n",
      "\n",
      "At iterate   13    f=  2.50331D-01    |proj g|=  7.55924D-02\n",
      "\n",
      "At iterate   14    f=  2.07730D-01    |proj g|=  6.73904D-02\n",
      "\n",
      "At iterate   15    f=  1.80986D-01    |proj g|=  3.24006D-01\n",
      "\n",
      "At iterate   16    f=  1.41467D-01    |proj g|=  7.96995D-02\n",
      "\n",
      "At iterate   17    f=  1.29729D-01    |proj g|=  6.53932D-02\n",
      "\n",
      "At iterate   18    f=  1.11399D-01    |proj g|=  6.69659D-02\n",
      "\n",
      "At iterate   19    f=  8.91635D-02    |proj g|=  6.50249D-02\n",
      "\n",
      "At iterate   20    f=  7.21366D-02    |proj g|=  7.72173D-02\n",
      "\n",
      "At iterate   21    f=  5.50677D-02    |proj g|=  3.18132D-02\n",
      "\n",
      "At iterate   22    f=  4.55097D-02    |proj g|=  2.76196D-02\n",
      "\n",
      "At iterate   23    f=  3.68607D-02    |proj g|=  3.59135D-02\n",
      "\n",
      "At iterate   24    f=  2.85186D-02    |proj g|=  3.14951D-02\n",
      "\n",
      "At iterate   25    f=  2.36410D-02    |proj g|=  3.79207D-02\n",
      "\n",
      "At iterate   26    f=  2.02545D-02    |proj g|=  2.27335D-02\n",
      "\n",
      "At iterate   27    f=  1.60657D-02    |proj g|=  1.31920D-02\n",
      "\n",
      "At iterate   28    f=  1.35858D-02    |proj g|=  3.52644D-02\n",
      "\n",
      "At iterate   29    f=  9.66485D-03    |proj g|=  1.71447D-02\n",
      "\n",
      "At iterate   30    f=  7.07963D-03    |proj g|=  8.19669D-03\n",
      "\n",
      "At iterate   31    f=  5.33497D-03    |proj g|=  1.32053D-02\n",
      "\n",
      "At iterate   32    f=  3.93660D-03    |proj g|=  5.83532D-03\n",
      "\n",
      "At iterate   33    f=  3.27965D-03    |proj g|=  3.31661D-03\n",
      "\n",
      "At iterate   34    f=  2.40292D-03    |proj g|=  3.52143D-03\n",
      "\n",
      "At iterate   35    f=  1.48099D-03    |proj g|=  2.19033D-03\n",
      "\n",
      "At iterate   36    f=  9.22196D-04    |proj g|=  7.35101D-03\n",
      "\n",
      "At iterate   37    f=  5.42011D-04    |proj g|=  1.55730D-03\n",
      "\n",
      "At iterate   38    f=  4.75179D-04    |proj g|=  1.06047D-03\n",
      "\n",
      "At iterate   39    f=  3.27721D-04    |proj g|=  7.00317D-04\n",
      "\n",
      "At iterate   40    f=  2.55640D-04    |proj g|=  9.74960D-04\n",
      "\n",
      "At iterate   41    f=  2.08387D-04    |proj g|=  6.43005D-04\n",
      "\n",
      "At iterate   42    f=  1.75262D-04    |proj g|=  5.02459D-04\n",
      "\n",
      "At iterate   43    f=  1.28151D-04    |proj g|=  3.34631D-04\n",
      "\n",
      "At iterate   44    f=  9.55229D-05    |proj g|=  5.68621D-04\n",
      "\n",
      "At iterate   45    f=  6.56491D-05    |proj g|=  2.45583D-04\n",
      "\n",
      "At iterate   46    f=  4.95189D-05    |proj g|=  1.91865D-04\n",
      "\n",
      "At iterate   47    f=  3.40351D-05    |proj g|=  8.12003D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      " 4810     47     49      1     0     0   8.120D-05   3.404D-05\n",
      "  F =   3.4035105238823097E-005\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp64.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1edd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccefc156",
   "metadata": {},
   "source": [
    "## Questions After Class\n",
    "\n",
    "### Roughly, how does the model know to use certain functions as the fitting becomes more complex (e.g. sin(x), ln(x), e^x)?\n",
    "\n",
    "It does not learn an analytical form; it just approximates it.\n",
    "\n",
    "### when doing the .score on the mlp does the limit vary or does it have a set limit on its own?\n",
    "\n",
    "\n",
    "\n",
    "### What is tensorflow used for that scikit cant do?\n",
    "\n",
    "Tensorflow can do more types of networks and has more options for training.  Most importantly, it has code optmizations so that you can use more complex hardware directly.\n",
    "\n",
    "### when you say weight, what does that mean?\n",
    "\n",
    "Weights are coefficients, or the weight of that feature.\n",
    "\n",
    "\n",
    "### what is an artificial neuron?\n",
    "\n",
    "An artificial neuron is one \"unit\" of calculation.  A neuron takes a weighted sum of all of its inputs (including a bias term) and passes it through an \"activation function\" that squashes the values of output into [0,1].\n",
    "\n",
    "### what real life problems require tensorflow?\n",
    "\n",
    "All modern ML applications are tensorflow, pytorch or similar.\n",
    "\n",
    "### What do the hidden layers of the neural network represent?\n",
    "\n",
    "We do not specify exactly what they represent up front; we can use model explanation techniques and visualization tools to examine them after the fact and try to interpret them if needed.\n",
    "\n",
    "\n",
    "\n",
    "### What is the best way to optimize a neural net? would it be jut adding more layers?ï»¿\n",
    "\n",
    "You could specify some of the parameters and use GridSearch as well. There are types of layers as well. We will see that later.\n",
    "\n",
    "\n",
    "\n",
    "### Are the weights given to the hidden layers initially random?\n",
    "\n",
    "Typically yes, they can be initialized randomly and then they are learned.\n",
    "\n",
    "<!--\n",
    "### on tensorflow playground, if we increase the weight is that increasing the amount we are feeding within the hidden layer?\n",
    "\n",
    "### Do the neurons' layers have to be specified in the models we are going to use, or they are already specified for each model?\n",
    "\n",
    "### Are hidden layers just a number of masks that help the function determine what the overall classification should be?\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "source_map": [
   12,
   46,
   55,
   60,
   68,
   70,
   75,
   87,
   89,
   93,
   97,
   103,
   107,
   111,
   115,
   119,
   131,
   135,
   137
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}