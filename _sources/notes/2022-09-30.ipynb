{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8171a73e",
   "metadata": {},
   "source": [
    "# Cleaning Data: fixing values\n",
    "\n",
    "So far, we've dealt with structural issues in data. but there's a lot more to\n",
    "cleaning.  \n",
    "\n",
    "Today,  we'll deal with how to fix the values within  the data.\n",
    "\n",
    "Examples of how values can be represented poorly:\n",
    "\n",
    "\n",
    "[Stanford Policy Lab Open Policing Project data readme](https://github.com/stanford-policylab/opp/blob/master/data_readme.md)\n",
    "[Propublica Machine Bias](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm) the \"How we acquired data\" section\n",
    "\n",
    "```{hint}\n",
    " you can treat this one proejct as multiple cleaned datasets and study it more carefully for A4.\n",
    "```\n",
    "\n",
    "## Admin\n",
    "\n",
    "````{margin}\n",
    "\n",
    "```{admonition} Hacktoberfest\n",
    "\n",
    "learn about Hacktoberfest](https://hacktoberfest.com/)\n",
    "```\n",
    "````\n",
    "\n",
    "- [watch this repo](https://github.com/rhodyprog4ds/BrownFall22) to get announcements\n",
    "- grading will be updated over the weekend!\n",
    "- remember to [accept](https://classroom.github.com/a/-7TUoBDE) [a4](https://rhodyprog4ds.github.io/BrownFall22/assignments/04-prepare.html)\n",
    "\n",
    "\n",
    "```{important}\n",
    "Use the Submit workflow on your Actions tab for each assignment\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3823d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np #\n",
    "na_toy_df = pd.DataFrame(data = [[1,3,4,5],[2 ,6, np.nan,4]])\n",
    "\n",
    "# make plots look nicer and increase font size\n",
    "sns.set_theme(font_scale=2)\n",
    "arabica_data_url = 'https://raw.githubusercontent.com/jldbc/coffee-quality-database/master/data/arabica_data_cleaned.csv'\n",
    "\n",
    "coffee_df = pd.read_csv(arabica_data_url)\n",
    "\n",
    "\n",
    "rhodyprog4ds_gh_events_url = 'https://api.github.com/orgs/rhodyprog4ds/events'\n",
    "course_gh_df = pd.read_json(rhodyprog4ds_gh_events_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe583fef",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "\n",
    "Dealing with missing data is a whole research area. There isn't one solution.\n",
    "\n",
    "\n",
    "[in 2020 there was a whole workshop on missing](https://artemiss-workshop.github.io/)\n",
    "\n",
    "one organizer is the main developer of [sci-kit learn](https://scikit-learn.org/stable/) the ML package we will use soon.  In a [2020 invited talk](https://static.sched.com/hosted_files/ray2020/08/Keynote-%20Easier%20Machine%20Learning%20Thoughts%20From%20Scikit-Learn%20-%20Ga%C3%ABl%20Varoquaux%2C%20Research%20Director%2C%20Inria.pdf) he listed more automatic handling as an active area of research  and a development goal for sklearn.\n",
    "\n",
    "There are also many classic approaches both when training and when [applying models](https://www.jmlr.org/papers/volume8/saar-tsechansky07a/saar-tsechansky07a.pdf).\n",
    "\n",
    "\n",
    "[example application in breast cancer detection](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.701.4234&rep=rep1&type=pdf)\n",
    "\n",
    "\n",
    "Even in pandas, dealing with [missing values](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html) is under [experimentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data-na)\n",
    " as to how to represent it symbolically\n",
    "\n",
    "\n",
    "Missing values even causes the [datatypes to change](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data-casting-rules-and-indexing)\n",
    "\n",
    "\n",
    "That said, there are are om\n",
    "Pandas gives a few basic tools:\n",
    "\n",
    "- dropna\n",
    "- fillna\n",
    "\n",
    "\n",
    "\n",
    "Dropping is a good choice when you otherwise have a lot of data and the data is\n",
    "missing at random.\n",
    "\n",
    "Dropping can be risky if it's not missing at random. For example, if we saw in\n",
    "the coffee data that one of the scores was missing for all of the rows from one\n",
    "country, or even just missing more often in one country, that could bias our\n",
    "results.  \n",
    "\n",
    "Filling can be good if you know how to fill reasonably, but don't have data to\n",
    "spare by dropping.  For example\n",
    "- you can approximate with another column\n",
    "- you can approximate with that column from other rows\n",
    "\n",
    "\n",
    "**whatever you do, document it**\n",
    "\n",
    "### Finding Missing Values\n",
    "\n",
    "Our skill in summarixing and getting overviews of data helps us know when we\n",
    "have a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a164de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311 entries, 0 to 1310\n",
      "Data columns (total 44 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             1311 non-null   int64  \n",
      " 1   Species                1311 non-null   object \n",
      " 2   Owner                  1304 non-null   object \n",
      " 3   Country.of.Origin      1310 non-null   object \n",
      " 4   Farm.Name              955 non-null    object \n",
      " 5   Lot.Number             270 non-null    object \n",
      " 6   Mill                   1001 non-null   object \n",
      " 7   ICO.Number             1165 non-null   object \n",
      " 8   Company                1102 non-null   object \n",
      " 9   Altitude               1088 non-null   object \n",
      " 10  Region                 1254 non-null   object \n",
      " 11  Producer               1081 non-null   object \n",
      " 12  Number.of.Bags         1311 non-null   int64  \n",
      " 13  Bag.Weight             1311 non-null   object \n",
      " 14  In.Country.Partner     1311 non-null   object \n",
      " 15  Harvest.Year           1264 non-null   object \n",
      " 16  Grading.Date           1311 non-null   object \n",
      " 17  Owner.1                1304 non-null   object \n",
      " 18  Variety                1110 non-null   object \n",
      " 19  Processing.Method      1159 non-null   object \n",
      " 20  Aroma                  1311 non-null   float64\n",
      " 21  Flavor                 1311 non-null   float64\n",
      " 22  Aftertaste             1311 non-null   float64\n",
      " 23  Acidity                1311 non-null   float64\n",
      " 24  Body                   1311 non-null   float64\n",
      " 25  Balance                1311 non-null   float64\n",
      " 26  Uniformity             1311 non-null   float64\n",
      " 27  Clean.Cup              1311 non-null   float64\n",
      " 28  Sweetness              1311 non-null   float64\n",
      " 29  Cupper.Points          1311 non-null   float64\n",
      " 30  Total.Cup.Points       1311 non-null   float64\n",
      " 31  Moisture               1311 non-null   float64\n",
      " 32  Category.One.Defects   1311 non-null   int64  \n",
      " 33  Quakers                1310 non-null   float64\n",
      " 34  Color                  1095 non-null   object \n",
      " 35  Category.Two.Defects   1311 non-null   int64  \n",
      " 36  Expiration             1311 non-null   object \n",
      " 37  Certification.Body     1311 non-null   object \n",
      " 38  Certification.Address  1311 non-null   object \n",
      " 39  Certification.Contact  1311 non-null   object \n",
      " 40  unit_of_measurement    1311 non-null   object \n",
      " 41  altitude_low_meters    1084 non-null   float64\n",
      " 42  altitude_high_meters   1084 non-null   float64\n",
      " 43  altitude_mean_meters   1084 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(24)\n",
      "memory usage: 450.8+ KB\n"
     ]
    }
   ],
   "source": [
    "coffee_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b680bb",
   "metadata": {},
   "source": [
    "### Example Filling\n",
    "\n",
    "The 'Lot.Number' has a lot of NaN values, how can we explore it?\n",
    "\n",
    "We can look at the type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e2a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df['Lot.Number'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f25c5",
   "metadata": {},
   "source": [
    "And we can look at the value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72fdc5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                             18\n",
       "020/17                         6\n",
       "019/17                         5\n",
       "2                              3\n",
       "102                            3\n",
       "                              ..\n",
       "11/23/0696                     1\n",
       "3-59-2318                      1\n",
       "8885                           1\n",
       "5055                           1\n",
       "017-053-0211/ 017-053-0212     1\n",
       "Name: Lot.Number, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df['Lot.Number'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e5f6af",
   "metadata": {},
   "source": [
    "We see that a lot are '1', maybe we know that when the data was collected, if the Farm only has one lot, some people recorded '1' and others left it as missing. So we could fill in with 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465a2b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    1\n",
       "8    1\n",
       "9    1\n",
       "Name: Lot.Number, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df['Lot.Number'].fillna(1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56ee95",
   "metadata": {},
   "source": [
    "Note that even after we called `fillna` we display it again and the original data is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb6d547d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "Name: Lot.Number, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df['Lot.Number'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d31014",
   "metadata": {},
   "source": [
    "To save the filled in column we have a few choices:\n",
    "- use the `inplace` parameter. This doesn't offer performance advantages, but does It still copies the object, but then reassigns the pointer. Its under discussion to [deprecate](https://github.com/pandas-dev/pandas/issues/16529)\n",
    "- write to a new DataFrame\n",
    "- add a column\n",
    "\n",
    "\n",
    "We'll use adding a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276d7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_df['lot_number_clean'] = coffee_df['Lot.Number'].fillna('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04306365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                             1059\n",
       "020/17                           6\n",
       "019/17                           5\n",
       "102                              3\n",
       "103                              3\n",
       "                              ... \n",
       "3-59-2318                        1\n",
       "8885                             1\n",
       "5055                             1\n",
       "MCCFWXA15/16                     1\n",
       "017-053-0211/ 017-053-0212       1\n",
       "Name: lot_number_clean, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df['lot_number_clean'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6b8be",
   "metadata": {},
   "source": [
    "### Example Dropping\n",
    "\n",
    "\n",
    "\n",
    "To illustrate how `dropna` works, we'll use the `shape` method after each call.  \n",
    "Dropna is going to drop either rows or columns. So we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34969243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1311, 45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48d745",
   "metadata": {},
   "source": [
    "By default, it drops any row with one or more `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8951412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11914958",
   "metadata": {},
   "source": [
    "We could instead tell it to only drop rows with `NaN` in a subset of the columns.\n",
    "We might do this if we were interested in studying the impact of altitude on the ratings ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33898215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 45)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df.dropna(subset=['altitude_low_meters']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e42e5",
   "metadata": {},
   "source": [
    "In the [Open Policing Project Data Summary](https://openpolicing.stanford.edu/data/) we saw that they made a summary information that showed which variables had at least 70% not missing values.  We can similarly choose to keep only variables that have more than a specific threshold of data, using the `thresh` parameter and `axis=1` to drop along columns.\n",
    "\n",
    "The `thresh` parameter requires an `int` not a fraction of the rows, so we can\n",
    "save the shape values to variables and then use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70de7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1311, 44)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows, ncols = coffee_df.shape\n",
    "coffee_df.dropna(thresh =.7*nrows,axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3912b5",
   "metadata": {},
   "source": [
    "This dataset is actually in pretty good shape, but if we use a more stringent threshold it drops more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "089a104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1311, 34)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows, ncols = coffee_df.shape\n",
    "coffee_df.dropna(thresh =.85*nrows,axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2f811",
   "metadata": {},
   "source": [
    "## Inconsistent values\n",
    "\n",
    "This was one of the things that many of you anticipated or had observed.  A useful way to investigate for this, is to use `value_counts` and sort them alphabetically by the values from the original data, so that similar ones will be consecutive in the list. Once we have the `value_counts()` Series, the values from the `coffee_df` become the index, so we use `sort_index`.\n",
    "\n",
    "Let's look at the `In.Country.Partner` column\n",
    "```\n",
    "coffee_df['In.Country.Partner'].value_counts().sort_index()\n",
    "```\n",
    "---\n",
    "We can see there's only one `Blossom Valley International\\n` but 58 `Blossom Valley International`, the former is likely a typo, especially since `\\n` is a special character for a newline. Similarly, with 'Specialty Coffee Ass' and 'Specialty Coffee Association'.\n",
    "---\n",
    "This is another job for dictionaries, we make one with the value to replace as the key and the value to insert as the value.\n",
    "```\n",
    "partner_corrections = {'Blossom Valley International\\n':'Blossom Valley International',\n",
    "  'Specialty Coffee Ass':'Specialty Coffee Association'}\n",
    "coffee_df['in_country_partner_clean'] = coffee_df['In.Country.Partner'].replace(\n",
    "  to_replace=partner_corrections)\n",
    "coffee_df['in_country_partner_clean'].value_counts().sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "## Fixing data at load time\n",
    "\n",
    "Some of the different parameters in `read_csv` can also fix how it reads in data.\n",
    "\n",
    "For example `header` can make somethign like this:\n",
    "\n",
    "![mulitindex img of excel file](https://github.com/rhodyprog4ds/BrownFall20/raw/main/img/multiindex.png)\n",
    "\n",
    "read in correctly.  \n",
    "\n",
    "\n",
    "\n",
    "## A Cleaning Data Recipe\n",
    "\n",
    "__not everything possible, but good enough for this course__\n",
    "\n",
    "\n",
    "1. Can you use parameters to read the data in better?\n",
    "1. Fix the index and column headers (making these easier to use makes the rest easier)\n",
    "1. Is the data strucutred well?\n",
    "1. Are there missing values?\n",
    "1. Do the datatypes match what you expect by looking at the head or a sample?\n",
    "1. Are categorical variables represented in usable way?\n",
    "1. Does your analysis require filtering or augmenting the data?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Further reading\n",
    "\n",
    "\n",
    "\n",
    "Instead of more practice with these manipulations, below are more\n",
    "examples of cleaning data to see how these types of manipulations get used.  \n",
    "Your goal here is not to memorize every possible thing, but to build a general\n",
    "idea of what good data looks like and good habits for cleaning data and keeping\n",
    "it reproducible.  \n",
    "- [Cleaning the Adult Dataset](https://ryanwingate.com/projects/machine-learning-data-prep/adult/adult-cleaning/)\n",
    "- [All Shades](https://github.com/the-pudding/data/tree/master/foundation-names#allshadescsv--allshadesr)\n",
    "\n",
    "Also here are some tips on general data management and organization.\n",
    "\n",
    "This article is a comprehensive [discussion of data cleaning](https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4).\n",
    "\n",
    "\n",
    "##  Questions \n",
    "\n",
    "```{important}\n",
    "I will add these later. I have a deadline tomorrow.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "source_map": [
   12,
   51,
   66,
   120,
   122,
   130,
   132,
   136,
   138,
   143,
   145,
   148,
   150,
   160,
   164,
   166,
   175,
   177,
   180,
   182,
   187,
   189,
   196,
   199,
   201,
   204
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}